{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as PJOIN\n",
    "import os\n",
    "from keras import optimizers, regularizers\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../DATA/GENERATED/TRAIN/\"\n",
    "DATA_FILES = [\"train_libpng_cal.csv\", \"train_dealii_cal.csv\", \"train_server_cal.csv\", \"handcrafted.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_training_data():\n",
    "    all_files = []\n",
    "    if DATA_FILES[0] == 'all':\n",
    "        for file in os.listdir(DATA_DIR):\n",
    "            if file[:2] == 'X_':\n",
    "                all_files.append(file[2:])\n",
    "    else:\n",
    "        all_files = DATA_FILES\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for file in all_files:\n",
    "        train_x = pd.read_csv(PJOIN(DATA_DIR,\"X_\"+file),header=None)\n",
    "        all_x.append(np.array(train_x))\n",
    "        train_y = pd.read_csv(PJOIN(DATA_DIR,\"Y_\"+file),header=None)\n",
    "        all_y.append(train_y)\n",
    "    \n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "    print(all_x.shape,all_y.shape)\n",
    "    all_y = all_y.reshape(all_y.shape[0])    \n",
    "    return all_x, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    return (x - np.mean(x,axis=0))/np.std(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10747, 12) (10747, 1)\n",
      "(10747, 12) (10747,)\n",
      "8173 416 0\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_all_training_data()\n",
    "train_x = normalize_data(train_x)\n",
    "train_y = train_y-1\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(np.sum(train_y==0), np.sum(train_y==1), np.sum(train_y==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(train_x))\n",
    "train_x = train_x[perm]\n",
    "train_y = train_y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(keras.Model):\n",
    "\n",
    "    def __init__(self, use_bn=False, use_dp=False, num_classes=3):\n",
    "        super(SimpleMLP, self).__init__(name='mlp')\n",
    "        self.use_bn = use_bn\n",
    "        self.use_dp = use_dp\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #self.dense1 = keras.layers.Dense(24, activation='relu',kernel_regularizer=regularizers.l2(0.001))\n",
    "        self.dense2 = keras.layers.Dense(20, activation='relu',kernel_regularizer=regularizers.l2(0.5))\n",
    "        self.dense3 = keras.layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.5))\n",
    "        self.op = keras.layers.Dense(num_classes, activation='softmax')\n",
    "        if self.use_dp:\n",
    "            self.dp1 = keras.layers.Dropout(0.5)\n",
    "            self.dp2 = keras.layers.Dropout(0.5)\n",
    "            self.dp3 = keras.layers.Dropout(0.5)\n",
    "            \n",
    "        if self.use_bn:\n",
    "            self.bn1 = keras.layers.BatchNormalization(axis=-1)\n",
    "            self.bn2 = keras.layers.BatchNormalization(axis=-1)\n",
    "            self.bn3 = keras.layers.BatchNormalization(axis=-1)\n",
    "            \n",
    "\n",
    "    def call(self, inputs):\n",
    "#         x = self.dense1(inputs)\n",
    "#         if self.use_dp:\n",
    "#             x = self.dp1(x)\n",
    "#         if self.use_bn:\n",
    "#             x = self.bn1(x)\n",
    "        x = self.dense2(inputs)\n",
    "        if self.use_dp:\n",
    "            x = self.dp2(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn2(x)\n",
    "        x = self.dense3(x)\n",
    "        if self.use_dp:\n",
    "            x = self.dp3(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn3(x)\n",
    "        return self.op(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmsprop = optimizers.rmsprop(lr=1*1e-5)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=rmsprop,\n",
    "                 metrics=['acc','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10747/10747 [==============================] - 0s 45us/step - loss: 8.6053 - acc: 0.7597 - categorical_accuracy: 0.7597\n",
      "Epoch 2/50\n",
      "10747/10747 [==============================] - 0s 40us/step - loss: 8.4421 - acc: 0.7624 - categorical_accuracy: 0.7624\n",
      "Epoch 3/50\n",
      "10747/10747 [==============================] - 0s 38us/step - loss: 8.2818 - acc: 0.7622 - categorical_accuracy: 0.7622\n",
      "Epoch 4/50\n",
      "10747/10747 [==============================] - 0s 39us/step - loss: 8.1250 - acc: 0.7747 - categorical_accuracy: 0.7747\n",
      "Epoch 5/50\n",
      "10747/10747 [==============================] - 0s 37us/step - loss: 7.9721 - acc: 0.7851 - categorical_accuracy: 0.7851\n",
      "Epoch 6/50\n",
      "10747/10747 [==============================] - 0s 41us/step - loss: 7.8209 - acc: 0.7760 - categorical_accuracy: 0.7760\n",
      "Epoch 7/50\n",
      "10747/10747 [==============================] - 0s 33us/step - loss: 7.6737 - acc: 0.7678 - categorical_accuracy: 0.7678\n",
      "Epoch 8/50\n",
      "10747/10747 [==============================] - 0s 32us/step - loss: 7.5299 - acc: 0.7567 - categorical_accuracy: 0.7567\n",
      "Epoch 9/50\n",
      "10747/10747 [==============================] - 0s 24us/step - loss: 7.3883 - acc: 0.7482 - categorical_accuracy: 0.7482\n",
      "Epoch 10/50\n",
      "10747/10747 [==============================] - 0s 25us/step - loss: 7.2505 - acc: 0.7371 - categorical_accuracy: 0.7371\n",
      "Epoch 11/50\n",
      "10747/10747 [==============================] - 0s 26us/step - loss: 7.1151 - acc: 0.7296 - categorical_accuracy: 0.7296\n",
      "Epoch 12/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.9830 - acc: 0.7248 - categorical_accuracy: 0.7248\n",
      "Epoch 13/50\n",
      "10747/10747 [==============================] - 0s 24us/step - loss: 6.8532 - acc: 0.7214 - categorical_accuracy: 0.7214\n",
      "Epoch 14/50\n",
      "10747/10747 [==============================] - 0s 24us/step - loss: 6.7273 - acc: 0.7177 - categorical_accuracy: 0.7177\n",
      "Epoch 15/50\n",
      "10747/10747 [==============================] - 0s 24us/step - loss: 6.6036 - acc: 0.7116 - categorical_accuracy: 0.7116\n",
      "Epoch 16/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.4831 - acc: 0.7058 - categorical_accuracy: 0.7058\n",
      "Epoch 17/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.3658 - acc: 0.7023 - categorical_accuracy: 0.7023\n",
      "Epoch 18/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.2505 - acc: 0.7008 - categorical_accuracy: 0.7008\n",
      "Epoch 19/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.1382 - acc: 0.6964 - categorical_accuracy: 0.6964\n",
      "Epoch 20/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 6.0291 - acc: 0.6853 - categorical_accuracy: 0.6853\n",
      "Epoch 21/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.9224 - acc: 0.6580 - categorical_accuracy: 0.6580\n",
      "Epoch 22/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.8184 - acc: 0.6511 - categorical_accuracy: 0.6511\n",
      "Epoch 23/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.7168 - acc: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 24/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.6180 - acc: 0.6193 - categorical_accuracy: 0.6193\n",
      "Epoch 25/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.5216 - acc: 0.5945 - categorical_accuracy: 0.5945\n",
      "Epoch 26/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.4278 - acc: 0.5696 - categorical_accuracy: 0.5696\n",
      "Epoch 27/50\n",
      "10747/10747 [==============================] - ETA: 0s - loss: 5.3306 - acc: 0.5690 - categorical_accuracy: 0.56 - 0s 23us/step - loss: 5.3364 - acc: 0.5727 - categorical_accuracy: 0.5727\n",
      "Epoch 28/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.2478 - acc: 0.6023 - categorical_accuracy: 0.6023\n",
      "Epoch 29/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.1616 - acc: 0.6085 - categorical_accuracy: 0.6085\n",
      "Epoch 30/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 5.0778 - acc: 0.6006 - categorical_accuracy: 0.6006\n",
      "Epoch 31/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.9967 - acc: 0.6145 - categorical_accuracy: 0.6145\n",
      "Epoch 32/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.9177 - acc: 0.6185 - categorical_accuracy: 0.6185\n",
      "Epoch 33/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.8407 - acc: 0.6058 - categorical_accuracy: 0.6058\n",
      "Epoch 34/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.7666 - acc: 0.5945 - categorical_accuracy: 0.5945\n",
      "Epoch 35/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.6944 - acc: 0.5925 - categorical_accuracy: 0.5925\n",
      "Epoch 36/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.6247 - acc: 0.5799 - categorical_accuracy: 0.5799\n",
      "Epoch 37/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.5568 - acc: 0.4401 - categorical_accuracy: 0.4401\n",
      "Epoch 38/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.4913 - acc: 0.4299 - categorical_accuracy: 0.4299\n",
      "Epoch 39/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.4279 - acc: 0.4295 - categorical_accuracy: 0.4295\n",
      "Epoch 40/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.3664 - acc: 0.4239 - categorical_accuracy: 0.4239\n",
      "Epoch 41/50\n",
      "10747/10747 [==============================] - 0s 22us/step - loss: 4.3071 - acc: 0.4283 - categorical_accuracy: 0.4283\n",
      "Epoch 42/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.2497 - acc: 0.4127 - categorical_accuracy: 0.4127\n",
      "Epoch 43/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.1942 - acc: 0.3749 - categorical_accuracy: 0.3749\n",
      "Epoch 44/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.1407 - acc: 0.3665 - categorical_accuracy: 0.3665\n",
      "Epoch 45/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.0890 - acc: 0.0906 - categorical_accuracy: 0.0906\n",
      "Epoch 46/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 4.0392 - acc: 0.0666 - categorical_accuracy: 0.0666\n",
      "Epoch 47/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 3.9912 - acc: 0.0523 - categorical_accuracy: 0.0523\n",
      "Epoch 48/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 3.9449 - acc: 0.0427 - categorical_accuracy: 0.0427\n",
      "Epoch 49/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 3.9004 - acc: 0.0466 - categorical_accuracy: 0.0466\n",
      "Epoch 50/50\n",
      "10747/10747 [==============================] - 0s 23us/step - loss: 3.8576 - acc: 0.0353 - categorical_accuracy: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e8cad7a20>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,epochs=50,class_weight={0:1,1:4,2:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(train_x)\n",
    "preds = preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 8569 1796\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(preds==0), np.sum(preds==1), np.sum(preds==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8173 416 2158\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_y==0), np.sum(train_y==1), np.sum(train_y==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.58638743, 0.02450694, 0.31737194]), array([0.02740732, 0.50480769, 0.26413346]), array([0.05236704, 0.04674457, 0.28831563]), array([8173,  416, 2158]))\n",
      "0.09342141993114357\n",
      "8173 416 416\n",
      "382 8569 1796\n"
     ]
    }
   ],
   "source": [
    "test = train_y\n",
    "print(precision_recall_fscore_support(test, preds))\n",
    "print(accuracy_score(test,preds))\n",
    "print(np.sum(test==0), np.sum(test==1), np.sum(test==1))\n",
    "print(np.sum(preds==0), np.sum(preds==1), np.sum(preds==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
