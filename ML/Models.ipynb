{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from os.path import join as PJOIN\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"DATA/GENERATED/TRAIN/\"\n",
    "DATA_FILES = [\"train_libpng_cal.csv\", \"train_dealii_cal.csv\", \"train_server_cal.csv\", \"handcrafted.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_training_data():\n",
    "    all_files = []\n",
    "    if DATA_FILES[0] == 'all':\n",
    "        for file in os.listdir(DATA_DIR):\n",
    "            if file[:2] == 'X_':\n",
    "                all_files.append(file[2:])\n",
    "    else:\n",
    "        all_files = DATA_FILES\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for file in all_files:\n",
    "        train_x = pd.read_csv(PJOIN(DATA_DIR,\"X_\"+file),header=None)\n",
    "        all_x.append(np.array(train_x))\n",
    "        train_y = pd.read_csv(PJOIN(DATA_DIR,\"Y_\"+file),header=None)\n",
    "        all_y.append(train_y)\n",
    "    \n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "    print(all_x.shape,all_y.shape)\n",
    "    all_y = all_y.reshape(all_y.shape[0])    \n",
    "    return all_x, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    return (x - np.mean(x,axis=0))/np.std(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10747, 12) (10747, 1)\n",
      "(10747, 12) (10747,)\n",
      "8173 416 2158\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_all_training_data()\n",
    "train_x = normalize_data(train_x)\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(np.sum(train_y==1), np.sum(train_y==2), np.sum(train_y==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runSVM(x, y):\n",
    "    print(\"Running SVM....\")\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "    clf = svm.SVC(kernel='linear', C=1,max_iter=1000000).fit(x_train, y_train)\n",
    "    return clf.predict(x_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-8401732371d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "preds, test = runSVM(train_x,train_y)\n",
    "print(precision_recall_fscore_support(test, preds))\n",
    "print(accuracy_score(test,preds))\n",
    "print(np.sum(test==1), np.sum(test==2), np.sum(test==3))\n",
    "print(np.sum(preds==1), np.sum(preds==2), np.sum(preds==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runDecisionTree(x, y):\n",
    "    print (\"Running Decision Tree....\")\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "    depth = []\n",
    "    for i in range(3,20):\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "        scores = cross_val_score(estimator=clf, X=x, y=y, cv=9, n_jobs=4)\n",
    "        depth.append((i,scores.mean()))\n",
    "        print(\"Depth: \",i,\"Score: \",depth[-1])\n",
    "    #print(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Tree....\n",
      "Depth:  3 Score:  (3, 0.7932195567574175)\n",
      "Depth:  4 Score:  (4, 0.7977316840052764)\n",
      "Depth:  5 Score:  (5, 0.7882743870724094)\n",
      "Depth:  6 Score:  (6, 0.7862990785424604)\n",
      "Depth:  7 Score:  (7, 0.785309900449658)\n",
      "Depth:  8 Score:  (8, 0.7757166094238281)\n",
      "Depth:  9 Score:  (9, 0.7776888871280684)\n",
      "Depth:  10 Score:  (10, 0.7745785572428616)\n",
      "Depth:  11 Score:  (11, 0.7745837635381051)\n",
      "Depth:  12 Score:  (12, 0.7768405420126813)\n",
      "Depth:  13 Score:  (13, 0.7779707354180116)\n",
      "Depth:  14 Score:  (14, 0.7783958981742659)\n",
      "Depth:  15 Score:  (15, 0.7789665440470219)\n",
      "Depth:  16 Score:  (16, 0.7796742535698135)\n",
      "Depth:  17 Score:  (17, 0.7761450390376046)\n",
      "Depth:  18 Score:  (18, 0.7723416853988806)\n",
      "Depth:  19 Score:  (19, 0.7750239890447346)\n"
     ]
    }
   ],
   "source": [
    "runDecisionTree(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ann(x,y):\n",
    "    print(\"Running ANN....\")\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                        hidden_layer_sizes=(20, 8), random_state=1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf.predict(x_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ANN....\n",
      "(array([0.80263158, 1.        , 0.68421053]), array([0.97181373, 0.31428571, 0.23214286]), array([0.87915743, 0.47826087, 0.34666667]), array([816,  35, 224]))\n",
      "0.7962790697674419\n",
      "816 35 224\n",
      "988 11 76\n"
     ]
    }
   ],
   "source": [
    "preds, test = run_ann(train_x, train_y)\n",
    "print(precision_recall_fscore_support(test, preds))\n",
    "print(accuracy_score(test,preds))\n",
    "print(np.sum(test==1), np.sum(test==2), np.sum(test==3))\n",
    "print(np.sum(preds==1), np.sum(preds==2), np.sum(preds==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSVM_CV(x, y):\n",
    "    print(\"Running SVM....\")\n",
    "    perm = np.random.permutation(len(x))\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    clf = svm.SVC(kernel='poly', degree=3, C=0.001)\n",
    "    return cross_val_predict(clf, x, y,cv=6),y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM....\n",
      "(array([0.78853985, 0.76744186, 0.8974359 ]), array([0.99510584, 0.07932692, 0.16218721]), array([0.87986152, 0.14379085, 0.27472527]), array([8173,  416, 2158]))\n",
      "0.7924071834000186\n",
      "8173 416 2158\n",
      "10314 43 390\n"
     ]
    }
   ],
   "source": [
    "preds, test = runSVM_CV(train_x, train_y)\n",
    "print(precision_recall_fscore_support(test, preds))\n",
    "print(accuracy_score(test,preds))\n",
    "print(np.sum(test==1), np.sum(test==2), np.sum(test==3))\n",
    "print(np.sum(preds==1), np.sum(preds==2), np.sum(preds==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ann_CV(x,y,plot_curve = False):\n",
    "    print(\"Running ANN....\")\n",
    "    perm = np.random.permutation(len(x))\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=10,\n",
    "                        hidden_layer_sizes=(60,40, 20, 8),learning_rate_init = 0.1)\n",
    "    \n",
    "    if plot_curve:\n",
    "        return learning_curve(clf, x, y, train_sizes=[50, 80, 110], cv=5)\n",
    "    else:\n",
    "        return cross_val_predict(clf, x, y,cv=6),y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ANN....\n",
      "(array([0.82062321, 0.67826087, 0.77660972]), array([0.97956687, 0.375     , 0.27386469]), array([0.89307825, 0.48297214, 0.4049332 ]), array([8173,  416, 2158]))\n",
      "0.8144598492602587\n",
      "8173 416 2158\n",
      "9756 230 761\n"
     ]
    }
   ],
   "source": [
    "preds, test = run_ann_CV(train_x, train_y)\n",
    "print(precision_recall_fscore_support(test, preds))\n",
    "print(accuracy_score(test,preds))\n",
    "print(np.sum(test==1), np.sum(test==2), np.sum(test==3))\n",
    "print(np.sum(preds==1), np.sum(preds==2), np.sum(preds==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ANN....\n",
      "[[0.92       0.8        0.8        0.8        0.8       ]\n",
      " [0.9375     0.7375     0.7375     0.7375     0.7375    ]\n",
      " [0.88181818 0.71818182 0.71818182 0.71818182 0.71818182]]\n",
      "[[0.76011158 0.76046512 0.76046512 0.76070764 0.76070764]\n",
      " [0.76011158 0.76046512 0.76046512 0.76070764 0.76070764]\n",
      " [0.76011158 0.76046512 0.76046512 0.76070764 0.76070764]]\n"
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores, valid_scores = run_ann_CV(train_x, train_y, True)\n",
    "print(train_scores)\n",
    "print(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM....\n",
      "Running ANN....\n"
     ]
    }
   ],
   "source": [
    "preds_svm, test_svm = runSVM_CV(train_x, train_y)\n",
    "pr_svm = precision_recall_fscore_support(test_svm, preds_svm)\n",
    "mpr_svm = precision_recall_fscore_support(test_svm, preds_svm,average='weighted')\n",
    "preds_ann, test_ann = run_ann_CV(train_x, train_y)\n",
    "pr_ann = precision_recall_fscore_support(test_ann, preds_ann)\n",
    "mpr_ann = precision_recall_fscore_support(test_ann, preds_ann,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "OUTPUT_FILE_NAME = \"ANALYSIS/summary_cal_handcrafted.csv\"\n",
    "with open(OUTPUT_FILE_NAME,'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Feature\",\"SVM\",\"ANN\"])\n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Num True Label 1\",np.sum(test_svm==1),np.sum(test_ann==1)])\n",
    "    writer.writerow([\"Num True Label 2\",np.sum(test_svm==2),np.sum(test_ann==2)])\n",
    "    writer.writerow([\"Num True Label 3\",np.sum(test_svm==3),np.sum(test_ann==3)])\n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Num Predicted Label 1\",np.sum(preds_svm==1),np.sum(preds_ann==1)])\n",
    "    writer.writerow([\"Num Predicted Label 2\",np.sum(preds_svm==2),np.sum(preds_ann==2)])\n",
    "    writer.writerow([\"Num Predicted Label 3\",np.sum(preds_svm==3),np.sum(preds_ann==3)])\n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Accuracy\",accuracy_score(test_svm,preds_svm),accuracy_score(test_ann, preds_ann)])\n",
    "    writer.writerow([\"Micro Precision\",mpr_svm[0],mpr_ann[0]])\n",
    "    writer.writerow([\"Micro Recall\",mpr_svm[1],mpr_ann[1]])    \n",
    "    writer.writerow([\"Micro F1\",mpr_svm[2],mpr_ann[2]])  \n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Precision for Label 1\",pr_svm[0][0],pr_ann[0][0]])\n",
    "    writer.writerow([\"Precision for Label 2\",pr_svm[1][0],pr_ann[1][0]])    \n",
    "    writer.writerow([\"Precision for Label 3\",pr_svm[2][0],pr_ann[2][0]])    \n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Recall for Label 1\",pr_svm[0][1],pr_ann[0][1]])\n",
    "    writer.writerow([\"Recall for Label 2\",pr_svm[1][1],pr_ann[1][1]])    \n",
    "    writer.writerow([\"Recall for Label 3\",pr_svm[2][1],pr_ann[2][1]])\n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"F1 for Label 1\",pr_svm[0][2],pr_ann[0][2]])\n",
    "    writer.writerow([\"F1 for Label 2\",pr_svm[1][2],pr_ann[1][2]])    \n",
    "    writer.writerow([\"F1 for Label 3\",pr_svm[2][2],pr_ann[2][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8006885642504885, 0.8006885642504885, 0.8006885642504884, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbls = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3649, 2, 7, 151)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lbls==0), np.sum(lbls==1), np.sum(lbls==2), np.sum(lbls==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7972454010832395, 0.8007816134735275, 0.7556246261013975, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpr_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.80392943, 0.95522388, 0.74147727]),\n",
       " array([0.98127982, 0.15384615, 0.24189064]),\n",
       " array([0.88379525, 0.26501035, 0.36477987]),\n",
       " array([8173,  416, 2158]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43831314, 8.61137821, 1.66002471])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_y),\n",
    "                                                 train_y)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
