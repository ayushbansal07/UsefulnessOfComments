{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, GlobalMaxPooling1D, Input, concatenate, Dropout, Reshape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_recall_fscore_support as fscore\n",
    "from sklearn.metrics.pairwise import cosine_similarity as CS\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLEANING_PATTERSN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()*]\")\n",
    "LSTM_HIDDEN_SIZE = 200\n",
    "MAX_TIME = 30\n",
    "VOCAB_SIZE = 10000\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 2000\n",
    "FILE_TYPE = 'all'\n",
    "MIDDLE_LAYER_ACTIVATION = 'relu'\n",
    "FINAL_LAYER_ACTIVATION = 'sigmoid'\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>ProgramDomain</th>\n",
       "      <th>ProjectManagement</th>\n",
       "      <th>ProblemDomain</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.15</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.65</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.727505</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1    F2    F3    F4    F5    F6    F7    F8         F9   F10   F11  \\\n",
       "0  0.75  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "1  9.15  3.65  0.05  2.21  0.59  0.05  0.05  0.05   3.610000  0.05  0.05   \n",
       "2  5.65  3.65  0.05  0.13  1.67  0.05  0.05  0.05  15.727505  0.05  0.05   \n",
       "3  3.55  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "4  0.75  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "\n",
       "    F12  ProgramDomain  ProjectManagement  ProblemDomain  Index  \n",
       "0  0.05              0                  0              0      0  \n",
       "1  0.05              1                  0              0      1  \n",
       "2  0.05              1                  0              1      2  \n",
       "3  0.05              0                  0              1      3  \n",
       "4  0.05              0                  0              0      4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = pd.read_csv('DATA/GENERATED/TRAIN/Z_CONCATED_commentType.csv',delimiter='\\t')\n",
    "FEATS = pd.read_csv('DATA/GENERATED/TRAIN/CONCATED_commentType_'+FILE_TYPE+'.csv')\n",
    "FEATS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = np.array(Z['F2'])\n",
    "X = np.array(FEATS)[:,:12]\n",
    "if FILE_TYPE == 'all':\n",
    "    Y = np.array(FEATS[['ProgramDomain','ProjectManagement','ProblemDomain']])\n",
    "else:\n",
    "    Y = np.array(FEATS['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = Counter()\n",
    "mp = {}\n",
    "sentences = []\n",
    "for comment in comments:\n",
    "    sent = [x.strip() for x in CLEANING_PATTERSN.split(comment) if x!='']\n",
    "    ctr[len(sent)] += 1\n",
    "    sentences.append(sent)\n",
    "    if len(sent) not in mp:\n",
    "        mp[len(sent)] = []\n",
    "    mp[len(sent)].append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = Counter()\n",
    "for sent in sentences:\n",
    "    for word in sent:\n",
    "        ctr[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7732"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sent = tokenizer.texts_to_sequences(sentences)\n",
    "train_sent = pad_sequences(train_sent, maxlen=MAX_TIME,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12774, 3)\n"
     ]
    }
   ],
   "source": [
    "if FILE_TYPE == 'all':\n",
    "    train_y = Y\n",
    "else:\n",
    "    train_y = to_categorical(Y)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11496\n",
      "(11496, 12) (11496, 3) (11496, 30) (1278, 12) (1278, 3) (1278, 30)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = int(0.9*len(X))\n",
    "print(NUM_TRAIN)\n",
    "train_x = X[:NUM_TRAIN]\n",
    "test_x = X[NUM_TRAIN:]\n",
    "train_y, test_y = train_y[:NUM_TRAIN], train_y[NUM_TRAIN:]\n",
    "train_sent, test_sent = train_sent[:NUM_TRAIN], train_sent[NUM_TRAIN:]\n",
    "print(train_x.shape, train_y.shape, train_sent.shape, test_x.shape, test_y.shape, test_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "def divide_into_k_folds(train_x, train_y, train_sent,k):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    sents = []\n",
    "    each = int(len(train_x)/k)\n",
    "    for i in range (k-1):\n",
    "        xs.append(train_x[i*each:(i+1)*each])\n",
    "        ys.append(train_y[i*each:(i+1)*each])\n",
    "        sents.append(train_sent[i*each:(i+1)*each])\n",
    "    xs.append(train_x[(k-1)*each:])\n",
    "    ys.append(train_y[(k-1)*each:])    \n",
    "    sents.append(train_sent[(k-1)*each:])    \n",
    "    return np.array(xs), np.array(ys), np.array(sents)\n",
    "\n",
    "train_x, train_y, train_sent = divide_into_k_folds(train_x, train_y, train_sent, K)\n",
    "print(train_x.shape)\n",
    "\n",
    "def get_fold(train_x, train_y, train_sent,i,k):\n",
    "    ids = [x for x in range(k) if x != i]\n",
    "    print(i,k,ids)\n",
    "    return np.concatenate(train_x[ids],axis=0), np.concatenate(train_y[ids],axis=0), \\\n",
    "        np.concatenate(train_sent[ids],axis=0)\n",
    "#     xs, ys, sents = train_x[0], train_y[0], train_sent[0]\n",
    "#     if i == 0:\n",
    "#         xs, ys, sents = train_x[1], train_y[1], train_sent[1]\n",
    "#     for j in range(1,k):\n",
    "#         if j == i:\n",
    "#             continue\n",
    "#         c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sent_input = Input(shape=(MAX_TIME,))\n",
    "    extracted_feats = Input(shape=(12,))\n",
    "    embeddingLayer = Embedding(VOCAB_SIZE, 100, input_length=MAX_TIME,  trainable=True)\n",
    "    sent = embeddingLayer(sent_input)\n",
    "    _, h1, c1 = LSTM(LSTM_HIDDEN_SIZE,dropout=DROPOUT,return_state=True)(sent)\n",
    "    print(h1.shape)\n",
    "    # Concat h1 and 12 features\n",
    "    feature_vector = concatenate([h1,extracted_feats],axis=1)\n",
    "    print(feature_vector.shape)\n",
    "    probs = Dense(64,activation=MIDDLE_LAYER_ACTIVATION)(feature_vector)\n",
    "    print(probs.shape)\n",
    "    probs = Dense(3,activation=FINAL_LAYER_ACTIVATION)(probs)\n",
    "    print(probs.shape)\n",
    "    model = Model(inputs=[sent_input,extracted_feats],outputs=probs)\n",
    "    rmsprop = optimizers.rmsprop(lr=LEARNING_RATE)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=rmsprop,\n",
    "                 metrics=['binary_accuracy','categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fs(model):\n",
    "    predictions = model.predict([test_sent,test_x],batch_size=BATCH_SIZE)\n",
    "    if FILE_TYPE == 'all':\n",
    "        predictions = np.where(predictions > 0.5,1,0)\n",
    "    else:\n",
    "        predictions = predictions.argmax(axis=1)\n",
    "    if FILE_TYPE == 'all':\n",
    "        fs = fscore(test_y,predictions)\n",
    "    else:\n",
    "        fs = fscore(test_y.argmax(axis=1),predictions)\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Running Fold -  1  of  5 -------------------\n",
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n",
      "0 5 [1, 2, 3, 4]\n",
      "(9197, 12)\n",
      "Train on 9197 samples, validate on 2299 samples\n",
      "Epoch 1/1\n",
      "9197/9197 [==============================] - 8s 904us/step - loss: 0.8532 - binary_accuracy: 0.4119 - categorical_accuracy: 0.0843 - val_loss: 0.8404 - val_binary_accuracy: 0.4731 - val_categorical_accuracy: 0.1479\n",
      "-----------------Running Fold -  2  of  5 -------------------\n",
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n",
      "1 5 [0, 2, 3, 4]\n",
      "(9197, 12)\n",
      "Train on 9197 samples, validate on 2299 samples\n",
      "Epoch 1/1\n",
      "9197/9197 [==============================] - 8s 863us/step - loss: 0.7756 - binary_accuracy: 0.4868 - categorical_accuracy: 0.2579 - val_loss: 0.7703 - val_binary_accuracy: 0.5675 - val_categorical_accuracy: 0.3667\n",
      "-----------------Running Fold -  3  of  5 -------------------\n",
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n",
      "2 5 [0, 1, 3, 4]\n",
      "(9197, 12)\n",
      "Train on 9197 samples, validate on 2299 samples\n",
      "Epoch 1/1\n",
      "9197/9197 [==============================] - 8s 888us/step - loss: 0.7671 - binary_accuracy: 0.4786 - categorical_accuracy: 0.5194 - val_loss: 0.7426 - val_binary_accuracy: 0.5653 - val_categorical_accuracy: 0.7712\n",
      "-----------------Running Fold -  4  of  5 -------------------\n",
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n",
      "3 5 [0, 1, 2, 4]\n",
      "(9197, 12)\n",
      "Train on 9197 samples, validate on 2299 samples\n",
      "Epoch 1/1\n",
      "9197/9197 [==============================] - 8s 866us/step - loss: 0.9559 - binary_accuracy: 0.3135 - categorical_accuracy: 0.0171 - val_loss: 0.9314 - val_binary_accuracy: 0.3430 - val_categorical_accuracy: 0.0239\n",
      "-----------------Running Fold -  5  of  5 -------------------\n",
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n",
      "4 5 [0, 1, 2, 3]\n",
      "(9196, 12)\n",
      "Train on 9196 samples, validate on 2300 samples\n",
      "Epoch 1/1\n",
      "9196/9196 [==============================] - 8s 900us/step - loss: 0.6753 - binary_accuracy: 0.6293 - categorical_accuracy: 0.9301 - val_loss: 0.6669 - val_binary_accuracy: 0.6939 - val_categorical_accuracy: 0.9287\n"
     ]
    }
   ],
   "source": [
    "MODELS = []\n",
    "FSS = []\n",
    "for k in range(K):\n",
    "    print(\"-----------------Running Fold - \",k+1,\" of \",K,\"-------------------\")\n",
    "    model = build_model()\n",
    "    MODELS.append(model)\n",
    "    curr_train_x, curr_train_y, curr_train_sent = get_fold(train_x, train_y, train_sent,k,K)\n",
    "    print(curr_train_x.shape)\n",
    "    model.fit([curr_train_sent,curr_train_x],curr_train_y,epochs=NUM_EPOCHS,batch_size=BATCH_SIZE,verbose=1,\n",
    "          validation_data=([train_sent[k], train_x[k]],train_y[k]))\n",
    "    FSS.append(find_fs(model))\n",
    "    model.save('model_'+FILE_TYPE+'_fold_'+str(k)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO CONTINUE TRAINING FOR MORE EPOCHS\n",
    "for k in range(K):\n",
    "    print(\"-----------------Running Fold - \",k+1,\" of \",K,\"-------------------\")\n",
    "    model = MODELS[k]\n",
    "    model.fit([train_sent[k],train_x[k]],train_y[k],epochs=NUM_EPOCHS,batch_size=BATCH_SIZE,verbose=1,\n",
    "          validation_data=([test_sent, test_x],test_y))\n",
    "    model.save('model_'+FILE_TYPE+'_fold_'+str(k)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict([test_sent,test_x],batch_size=BATCH_SIZE)\n",
    "if FILE_TYPE == 'all':\n",
    "    predictions = np.where(predictions > 0.5,1,0)\n",
    "else:\n",
    "    predictions = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FILE_TYPE == 'all':\n",
    "    fs = fscore(test_y,predictions)\n",
    "else:\n",
    "    fs = fscore(test_y.argmax(axis=1),predictions)\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_'+FILE_TYPE+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visulaising Embeddings\n",
    "embeddings = model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed(word):\n",
    "    return embeddings[tokenizer.word_index[word]].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_WORDS_FOR_ANALYSIS = 50\n",
    "SIM = []\n",
    "ALL_WORDS = []\n",
    "all_words = tokenizer.word_index.keys()\n",
    "for word in all_words:\n",
    "    ALL_WORDS.append(word)\n",
    "all_words = ALL_WORDS\n",
    "for i in range(NUM_WORDS_FOR_ANALYSIS):\n",
    "    for j in range(i+1,NUM_WORDS_FOR_ANALYSIS):\n",
    "        SIM.append((all_words[i],all_words[j],CS(embed(all_words[i]),embed(all_words[j]))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS = sorted(SIM,reverse=True,key=(lambda x:abs(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne_plot():\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in all_words[:50]:\n",
    "        tokens.append(embed(word)[0])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    #plt.show()\n",
    "    plt.savefig('SP.svg',format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
