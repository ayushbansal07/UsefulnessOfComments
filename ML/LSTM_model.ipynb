{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, GlobalMaxPooling1D, Input, concatenate, Dropout, Reshape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_recall_fscore_support as fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLEANING_PATTERSN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()*]\")\n",
    "LSTM_HIDDEN_SIZE = 200\n",
    "MAX_TIME = 30\n",
    "VOCAB_SIZE = 10000\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 2000\n",
    "FILE_TYPE = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>ProgramDomain</th>\n",
       "      <th>ProjectManagement</th>\n",
       "      <th>ProblemDomain</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.15</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.65</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.727505</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1    F2    F3    F4    F5    F6    F7    F8         F9   F10   F11  \\\n",
       "0  0.75  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "1  9.15  3.65  0.05  2.21  0.59  0.05  0.05  0.05   3.610000  0.05  0.05   \n",
       "2  5.65  3.65  0.05  0.13  1.67  0.05  0.05  0.05  15.727505  0.05  0.05   \n",
       "3  3.55  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "4  0.75  0.05  0.05  0.77  0.23  0.05  0.05  0.05   0.410000  0.05  0.05   \n",
       "\n",
       "    F12  ProgramDomain  ProjectManagement  ProblemDomain  Index  \n",
       "0  0.05              0                  0              0      0  \n",
       "1  0.05              1                  0              0      1  \n",
       "2  0.05              1                  0              1      2  \n",
       "3  0.05              0                  0              1      3  \n",
       "4  0.05              0                  0              0      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = pd.read_csv('DATA/GENERATED/TRAIN/Z_CONCATED_commentType.csv',delimiter='\\t')\n",
    "FEATS = pd.read_csv('DATA/GENERATED/TRAIN/CONCATED_commentType_'+FILE_TYPE+'.csv')\n",
    "FEATS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = np.array(Z['F2'])\n",
    "X = np.array(FEATS)[:,:12]\n",
    "if FILE_TYPE == 'all':\n",
    "    Y = np.array(FEATS[['ProgramDomain','ProjectManagement','ProblemDomain']])\n",
    "else:\n",
    "    Y = np.array(FEATS['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = Counter()\n",
    "mp = {}\n",
    "sentences = []\n",
    "for comment in comments:\n",
    "    sent = [x.strip() for x in CLEANING_PATTERSN.split(comment) if x!='']\n",
    "    ctr[len(sent)] += 1\n",
    "    sentences.append(sent)\n",
    "    if len(sent) not in mp:\n",
    "        mp[len(sent)] = []\n",
    "    mp[len(sent)].append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = Counter()\n",
    "for sent in sentences:\n",
    "    for word in sent:\n",
    "        ctr[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = len(ctr)+1\n",
    "# VOCAB = ['<UNK>']\n",
    "# for el in ctr:\n",
    "#     VOCAB.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7732"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sent = tokenizer.texts_to_sequences(sentences)\n",
    "train_sent = pad_sequences(train_sent, maxlen=MAX_TIME,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12774, 3)\n"
     ]
    }
   ],
   "source": [
    "if FILE_TYPE == 'all':\n",
    "    train_y = Y\n",
    "else:\n",
    "    train_y = to_categorical(Y)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11496\n",
      "(11496, 12) (11496, 3) (11496, 30) (1278, 12) (1278, 3) (1278, 30)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = int(0.9*len(X))\n",
    "print(NUM_TRAIN)\n",
    "train_x = X[:NUM_TRAIN]\n",
    "test_x = X[NUM_TRAIN:]\n",
    "train_y, test_y = train_y[:NUM_TRAIN], train_y[NUM_TRAIN:]\n",
    "train_sent, test_sent = train_sent[:NUM_TRAIN], train_sent[NUM_TRAIN:]\n",
    "print(train_x.shape, train_y.shape, train_sent.shape, test_x.shape, test_y.shape, test_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sent_input = Input(shape=(MAX_TIME,))\n",
    "    extracted_feats = Input(shape=(12,))\n",
    "    embeddingLayer = Embedding(VOCAB_SIZE, 100, input_length=MAX_TIME,  trainable=True)\n",
    "    sent = embeddingLayer(sent_input)\n",
    "    _, h1, c1 = LSTM(LSTM_HIDDEN_SIZE,dropout=DROPOUT,return_state=True)(sent)\n",
    "    print(h1.shape)\n",
    "    # Concat h1 and 12 features\n",
    "    feature_vector = concatenate([h1,extracted_feats],axis=1)\n",
    "    print(feature_vector.shape)\n",
    "    probs = Dense(64,activation='relu')(feature_vector)\n",
    "    print(probs.shape)\n",
    "    probs = Dense(3,activation='sigmoid')(probs)\n",
    "    print(probs.shape)\n",
    "    model = Model(inputs=[sent_input,extracted_feats],outputs=probs)\n",
    "    rmsprop = optimizers.rmsprop(lr=LEARNING_RATE)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=rmsprop,\n",
    "                 metrics=['binary_accuracy','categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200)\n",
      "(?, 212)\n",
      "(?, 64)\n",
      "(?, 3)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11496 samples, validate on 1278 samples\n",
      "Epoch 1/100\n",
      "11496/11496 [==============================] - 10s 879us/step - loss: 0.6260 - binary_accuracy: 0.7739 - categorical_accuracy: 0.8164 - val_loss: 0.5880 - val_binary_accuracy: 0.7906 - val_categorical_accuracy: 0.8638\n",
      "Epoch 2/100\n",
      "11496/11496 [==============================] - 8s 700us/step - loss: 0.5336 - binary_accuracy: 0.8134 - categorical_accuracy: 0.9101 - val_loss: 0.4840 - val_binary_accuracy: 0.8169 - val_categorical_accuracy: 0.9272\n",
      "Epoch 3/100\n",
      "11496/11496 [==============================] - 8s 702us/step - loss: 0.4496 - binary_accuracy: 0.8306 - categorical_accuracy: 0.9431 - val_loss: 0.4561 - val_binary_accuracy: 0.8252 - val_categorical_accuracy: 0.9366\n",
      "Epoch 4/100\n",
      "11496/11496 [==============================] - 9s 748us/step - loss: 0.4276 - binary_accuracy: 0.8349 - categorical_accuracy: 0.9494 - val_loss: 0.4406 - val_binary_accuracy: 0.8271 - val_categorical_accuracy: 0.9374\n",
      "Epoch 5/100\n",
      "11496/11496 [==============================] - 9s 747us/step - loss: 0.4142 - binary_accuracy: 0.8368 - categorical_accuracy: 0.9515 - val_loss: 0.4277 - val_binary_accuracy: 0.8297 - val_categorical_accuracy: 0.9382\n",
      "Epoch 6/100\n",
      "11496/11496 [==============================] - 9s 774us/step - loss: 0.4028 - binary_accuracy: 0.8377 - categorical_accuracy: 0.9530 - val_loss: 0.4168 - val_binary_accuracy: 0.8312 - val_categorical_accuracy: 0.9382\n",
      "Epoch 7/100\n",
      "11496/11496 [==============================] - 9s 804us/step - loss: 0.3933 - binary_accuracy: 0.8386 - categorical_accuracy: 0.9543 - val_loss: 0.4084 - val_binary_accuracy: 0.8315 - val_categorical_accuracy: 0.9390\n",
      "Epoch 8/100\n",
      "11496/11496 [==============================] - 9s 745us/step - loss: 0.3860 - binary_accuracy: 0.8449 - categorical_accuracy: 0.9550 - val_loss: 0.4011 - val_binary_accuracy: 0.8323 - val_categorical_accuracy: 0.9390\n",
      "Epoch 9/100\n",
      "11496/11496 [==============================] - 9s 774us/step - loss: 0.3799 - binary_accuracy: 0.8468 - categorical_accuracy: 0.9555 - val_loss: 0.3953 - val_binary_accuracy: 0.8336 - val_categorical_accuracy: 0.9397\n",
      "Epoch 10/100\n",
      "11496/11496 [==============================] - 11s 997us/step - loss: 0.3749 - binary_accuracy: 0.8484 - categorical_accuracy: 0.9558 - val_loss: 0.3905 - val_binary_accuracy: 0.8367 - val_categorical_accuracy: 0.9397\n",
      "Epoch 11/100\n",
      "11496/11496 [==============================] - 10s 863us/step - loss: 0.3694 - binary_accuracy: 0.8533 - categorical_accuracy: 0.9562 - val_loss: 0.3887 - val_binary_accuracy: 0.8511 - val_categorical_accuracy: 0.9413\n",
      "Epoch 12/100\n",
      "11496/11496 [==============================] - 8s 735us/step - loss: 0.3655 - binary_accuracy: 0.8564 - categorical_accuracy: 0.9568 - val_loss: 0.3825 - val_binary_accuracy: 0.8401 - val_categorical_accuracy: 0.9421\n",
      "Epoch 13/100\n",
      "11496/11496 [==============================] - 8s 737us/step - loss: 0.3596 - binary_accuracy: 0.8588 - categorical_accuracy: 0.9569 - val_loss: 0.3800 - val_binary_accuracy: 0.8545 - val_categorical_accuracy: 0.9429\n",
      "Epoch 14/100\n",
      "11496/11496 [==============================] - 9s 742us/step - loss: 0.3567 - binary_accuracy: 0.8597 - categorical_accuracy: 0.9572 - val_loss: 0.3749 - val_binary_accuracy: 0.8485 - val_categorical_accuracy: 0.9437\n",
      "Epoch 15/100\n",
      "11496/11496 [==============================] - 9s 744us/step - loss: 0.3499 - binary_accuracy: 0.8620 - categorical_accuracy: 0.9577 - val_loss: 0.3711 - val_binary_accuracy: 0.8581 - val_categorical_accuracy: 0.9437\n",
      "Epoch 16/100\n",
      "11496/11496 [==============================] - 8s 738us/step - loss: 0.3440 - binary_accuracy: 0.8666 - categorical_accuracy: 0.9576 - val_loss: 0.3678 - val_binary_accuracy: 0.8597 - val_categorical_accuracy: 0.9452\n",
      "Epoch 17/100\n",
      "11496/11496 [==============================] - 8s 726us/step - loss: 0.3403 - binary_accuracy: 0.8662 - categorical_accuracy: 0.9576 - val_loss: 0.3651 - val_binary_accuracy: 0.8605 - val_categorical_accuracy: 0.9452\n",
      "Epoch 18/100\n",
      "11496/11496 [==============================] - 8s 731us/step - loss: 0.3343 - binary_accuracy: 0.8705 - categorical_accuracy: 0.9577 - val_loss: 0.3585 - val_binary_accuracy: 0.8631 - val_categorical_accuracy: 0.9452\n",
      "Epoch 19/100\n",
      "11496/11496 [==============================] - 8s 725us/step - loss: 0.3281 - binary_accuracy: 0.8711 - categorical_accuracy: 0.9578 - val_loss: 0.3535 - val_binary_accuracy: 0.8625 - val_categorical_accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "11496/11496 [==============================] - 9s 742us/step - loss: 0.3237 - binary_accuracy: 0.8706 - categorical_accuracy: 0.9578 - val_loss: 0.3481 - val_binary_accuracy: 0.8633 - val_categorical_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "11496/11496 [==============================] - 9s 802us/step - loss: 0.3165 - binary_accuracy: 0.8734 - categorical_accuracy: 0.9573 - val_loss: 0.3418 - val_binary_accuracy: 0.8623 - val_categorical_accuracy: 0.9437\n",
      "Epoch 22/100\n",
      "11496/11496 [==============================] - 9s 747us/step - loss: 0.3138 - binary_accuracy: 0.8730 - categorical_accuracy: 0.9573 - val_loss: 0.3391 - val_binary_accuracy: 0.8644 - val_categorical_accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "11496/11496 [==============================] - 9s 771us/step - loss: 0.3069 - binary_accuracy: 0.8760 - categorical_accuracy: 0.9574 - val_loss: 0.3355 - val_binary_accuracy: 0.8636 - val_categorical_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "11496/11496 [==============================] - 8s 736us/step - loss: 0.3020 - binary_accuracy: 0.8771 - categorical_accuracy: 0.9569 - val_loss: 0.3369 - val_binary_accuracy: 0.8623 - val_categorical_accuracy: 0.9444\n",
      "Epoch 25/100\n",
      "11496/11496 [==============================] - 8s 739us/step - loss: 0.3000 - binary_accuracy: 0.8781 - categorical_accuracy: 0.9566 - val_loss: 0.3285 - val_binary_accuracy: 0.8665 - val_categorical_accuracy: 0.9437\n",
      "Epoch 26/100\n",
      "11496/11496 [==============================] - 9s 747us/step - loss: 0.2930 - binary_accuracy: 0.8803 - categorical_accuracy: 0.9567 - val_loss: 0.3383 - val_binary_accuracy: 0.8636 - val_categorical_accuracy: 0.9437\n",
      "Epoch 27/100\n",
      "11496/11496 [==============================] - 11s 943us/step - loss: 0.2924 - binary_accuracy: 0.8811 - categorical_accuracy: 0.9563 - val_loss: 0.3230 - val_binary_accuracy: 0.8714 - val_categorical_accuracy: 0.9437\n",
      "Epoch 28/100\n",
      "11496/11496 [==============================] - 9s 774us/step - loss: 0.2842 - binary_accuracy: 0.8859 - categorical_accuracy: 0.9566 - val_loss: 0.3217 - val_binary_accuracy: 0.8730 - val_categorical_accuracy: 0.9421\n",
      "Epoch 29/100\n",
      "11496/11496 [==============================] - 9s 742us/step - loss: 0.2886 - binary_accuracy: 0.8837 - categorical_accuracy: 0.9558 - val_loss: 0.3171 - val_binary_accuracy: 0.8748 - val_categorical_accuracy: 0.9421\n",
      "Epoch 30/100\n",
      "11496/11496 [==============================] - 9s 778us/step - loss: 0.2786 - binary_accuracy: 0.8874 - categorical_accuracy: 0.9563 - val_loss: 0.3191 - val_binary_accuracy: 0.8709 - val_categorical_accuracy: 0.9437\n",
      "Epoch 31/100\n",
      "11496/11496 [==============================] - 9s 757us/step - loss: 0.2786 - binary_accuracy: 0.8874 - categorical_accuracy: 0.9555 - val_loss: 0.3151 - val_binary_accuracy: 0.8732 - val_categorical_accuracy: 0.9429\n",
      "Epoch 32/100\n",
      "11496/11496 [==============================] - 9s 823us/step - loss: 0.2749 - binary_accuracy: 0.8882 - categorical_accuracy: 0.9556 - val_loss: 0.3136 - val_binary_accuracy: 0.8745 - val_categorical_accuracy: 0.9421\n",
      "Epoch 33/100\n",
      "11496/11496 [==============================] - 10s 844us/step - loss: 0.2724 - binary_accuracy: 0.8907 - categorical_accuracy: 0.9549 - val_loss: 0.3187 - val_binary_accuracy: 0.8704 - val_categorical_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "11496/11496 [==============================] - 10s 848us/step - loss: 0.2686 - binary_accuracy: 0.8926 - categorical_accuracy: 0.9550 - val_loss: 0.3190 - val_binary_accuracy: 0.8704 - val_categorical_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "11496/11496 [==============================] - 9s 767us/step - loss: 0.2675 - binary_accuracy: 0.8939 - categorical_accuracy: 0.9549 - val_loss: 0.3136 - val_binary_accuracy: 0.8777 - val_categorical_accuracy: 0.9429\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11496/11496 [==============================] - 9s 761us/step - loss: 0.2634 - binary_accuracy: 0.8939 - categorical_accuracy: 0.9541 - val_loss: 0.3062 - val_binary_accuracy: 0.8798 - val_categorical_accuracy: 0.9429\n",
      "Epoch 37/100\n",
      "11496/11496 [==============================] - 9s 783us/step - loss: 0.2596 - binary_accuracy: 0.8985 - categorical_accuracy: 0.9538 - val_loss: 0.3140 - val_binary_accuracy: 0.8766 - val_categorical_accuracy: 0.9437\n",
      "Epoch 38/100\n",
      "11496/11496 [==============================] - 9s 762us/step - loss: 0.2636 - binary_accuracy: 0.8939 - categorical_accuracy: 0.9550 - val_loss: 0.3056 - val_binary_accuracy: 0.8816 - val_categorical_accuracy: 0.9421\n",
      "Epoch 39/100\n",
      "10000/11496 [=========================>....] - ETA: 1s - loss: 0.2562 - binary_accuracy: 0.8988 - categorical_accuracy: 0.9533"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0ea06f1b2f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([train_sent,train_x],train_y,epochs=NUM_EPOCHS,batch_size=BATCH_SIZE,verbose=1,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=([test_sent, test_x],test_y))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([train_sent,train_x],train_y,epochs=NUM_EPOCHS,batch_size=BATCH_SIZE,verbose=1,\n",
    "          validation_data=([test_sent, test_x],test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict([test_sent,test_x],batch_size=BATCH_SIZE)\n",
    "if FILE_TYPE == 'all':\n",
    "    predictions = np.where(predictions > 0.5,1,0)\n",
    "else:\n",
    "    predictions = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87406015, 0.90740741, 0.82517483]),\n",
       " array([0.93467337, 0.33333333, 0.48163265]),\n",
       " array([0.90335114, 0.48756219, 0.60824742]),\n",
       " array([995, 147, 245]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if FILE_TYPE == 'all':\n",
    "    fs = fscore(test_y,predictions)\n",
    "else:\n",
    "    fs = fscore(test_y.argmax(axis=1),predictions)\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_'+FILE_TYPE+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
